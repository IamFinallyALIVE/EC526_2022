SEE 4 Lecture Notes: Parallelization Methods
(Can ignore OpenMP threads which is essentially the same as OpenACC)

MPI Examples:

n00HelloWorld:         NO communication NO computatoin
n01VectoAdd_Timing:    Add 2 vectors but  NO  communication
n04Integrate:          Timing with Only one  reduce commuicatin
n05Jacobi              Real problem Comnmunicate wit Send-Receive

=============== Ok Here is MPI light ==============

To run  on command line.

bash
module load gcc
module load  mvapich/2.3.3

There is of course a scalar code before MPIing it
g++  scal_hello.cpp -o scal_hello
./scal_hello

mpicc  mpi_hello.cpp -o mpi_hello

mpirun -np  64  ./mpi_hello

Note order of Hello,s 

See lots of nice stuff at

https://www.bu.edu/tech/support/research/training-consulting/online-tutorials/mpi/example1-2
/
 
---- Ok can use a script queue by a script ---

by

qsub -l h_rt=0:05:00 -P paralg submit_mpi_hello.sh

http://www.bu.edu/tech/support/research/system-usage/running-jobs/submitting-jobs/

look at it by

qstat -u brower


--- Now Jacobi --

mpicxx -std=c++11  jacobi_mpi.cpp -o  jacobi_mpi


         COMMENT ON  C CODE: 
g++ jacob_scal.cpp  -o jacobi_scal   (not gcc?) 

mpicc -lm  jacobi_mpi.cpp -o jacobi_mpi   C method

I had to attach -lm to the compile instruction
and get rid of the C++ "new" syntac for malloc

    x = (double*)malloc(local_size * sizeof(double));
    xtmp = (double*)malloc(local_size * sizeof(double));
    b = (double*)malloc(local_size * sizeof(double));

C++ method (Can use mpicxx on scalar code too.)


Asking for nodes to run MPI in interactive mode 
https://www.bu.edu/tech/support/research/system-usage/running-jobs/interactive-mpi/


qsh -pe mpi_16_tasks_per_node 32 -now n'

Then to use two MPI with rank 0,1 
mpirun -np 32 ./your_mpi_binary

